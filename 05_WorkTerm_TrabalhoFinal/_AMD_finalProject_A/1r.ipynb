{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_______________________________________________________\n",
      "(1R-approach) >>Error Matrix>> isastigmatic & lenses <<\n",
      "('hard', 'none', 'soft')\n",
      "('false', 'true')\n",
      "[[1.         0.33333333]\n",
      " [0.25       1.        ]\n",
      " [0.75       0.66666667]]\n",
      "\n",
      "1R for the 'isastigmatic' feature are:\n",
      "(isastigmatic, false, none) : 0.250\n",
      "(isastigmatic, true, hard) : 0.333\n"
     ]
    }
   ],
   "source": [
    "# to use accented characters in the code\n",
    "# -*- coding: cp1252 -*-\n",
    "# ===============================\n",
    "# author: Paulo Trigo Silva (PTS)\n",
    "# version: v07 (Python3)\n",
    "# ===============================\n",
    "\n",
    "\n",
    "# __________________________________________\n",
    "# Orange Documentation:\n",
    "# http://docs.orange.biolab.si\n",
    "#\n",
    "# Orange Reference Manual:\n",
    "# http://docs.orange.biolab.si/3/data-mining-library/#reference\n",
    "#\n",
    "# Tutorial:\n",
    "# http://docs.orange.biolab.si/3/data-mining-library/#tutorial\n",
    "#\n",
    "# details about data (attribute+class) characterization:\n",
    "# http://docs.orange.biolab.si/3/data-mining-library/tutorial/data.html#data-input\n",
    "# __________________________________________\n",
    "\n",
    "# _______________________________________________________________________________\n",
    "# Modules to Evaluate\n",
    "import sys\n",
    "from u01_util import my_print\n",
    "import Orange as DM\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# _______________________________________________________________________________\n",
    "# Auxiliary Functions\n",
    "# _______________________________________________________________________________\n",
    "# load the dataset\n",
    "def load(fileName):\n",
    "    try:\n",
    "        dataset = DM.data.Table(fileName)\n",
    "    except:\n",
    "        my_print(\"--->>> error - can not open the file: %s\" % fileName)\n",
    "        exit()\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# _______________________________________________________________________________\n",
    "# get the variable dataset-structure given a string with its name\n",
    "def get_variableFrom_str(dataset, str_name):\n",
    "    variable_list = dataset.domain.variables\n",
    "    for variable in variable_list:\n",
    "        if(variable.name == str_name):\n",
    "            return variable\n",
    "    my_print(\">>error>> \\\"{}\\\" is not a variable name in dataset!\".format(str_name))\n",
    "    return None\n",
    "\n",
    "\n",
    "# _______________________________________________________________________________\n",
    "# Data Analysis Functions\n",
    "# _______________________________________________________________________________\n",
    "# percentage of missing values of each variable\n",
    "def get_missingValuePercentage(dataset):\n",
    "    variable_list = dataset.domain.variables\n",
    "    var_len = len(variable_list)\n",
    "    missingValue_list = [0.0] * var_len\n",
    "    for instance in dataset:\n",
    "        for var_index in range(var_len):\n",
    "            if np.isnan(instance[var_index]):\n",
    "                missingValue_list[var_index] += 1\n",
    "    missingValue_list = list(map(lambda x, dim=len(dataset): x / dim*100.0, missingValue_list))\n",
    "    return (variable_list, missingValue_list)\n",
    "\n",
    "\n",
    "# _______________________________________________________________________________\n",
    "# contingencyMatrix; i.e., the joint-frequency table\n",
    "# this implementation does not account for missing-values\n",
    "# (i.e., missing-values are not included in the variables-domain)\n",
    "# M(row, column)\n",
    "def get_contingencyMatrix(dataset, rowVar, colVar):\n",
    "    if(isinstance(rowVar, str)):\n",
    "        rowVar = get_variableFrom_str(dataset, rowVar)\n",
    "    if(isinstance(colVar, str)):\n",
    "        colVar = get_variableFrom_str(dataset, colVar)\n",
    "    if(not (rowVar and colVar)):\n",
    "        return ([], [], None)\n",
    "    if(not (rowVar.is_discrete and colVar.is_discrete)):\n",
    "        my_print(\">>error>> variables are expected to be discrete\")\n",
    "        return ([], [], None)\n",
    "\n",
    "    rowDomain, colDomain = rowVar.values, colVar.values\n",
    "    len_rowDomain, len_colDomain = len(rowDomain), len(colDomain)\n",
    "    contingencyMatrix = np.zeros((len_rowDomain, len_colDomain))\n",
    "    for instance in dataset:\n",
    "        rowValue, colValue = instance[rowVar], instance[colVar]\n",
    "        if(np.isnan(rowValue) or np.isnan(colValue)):\n",
    "            continue\n",
    "\n",
    "        rowIndex, colIndex = rowDomain.index(rowValue), colDomain.index(colValue)\n",
    "        contingencyMatrix[rowIndex, colIndex] += 1\n",
    "    return (rowDomain, colDomain, contingencyMatrix)\n",
    "\n",
    "\n",
    "# _______________________________________________________________________________\n",
    "# P( H | E )\n",
    "# H means Hypothesis, E means Evidence\n",
    "# a frequency approach\n",
    "def get_conditionalProbability(dataset, H, E):\n",
    "    if(isinstance(H, str)):\n",
    "        H = get_variableFrom_str(dataset, H)\n",
    "    if(isinstance(E, str)):\n",
    "        E = get_variableFrom_str(dataset, E)\n",
    "    if(not (H and E)):\n",
    "        return ([], [], None)\n",
    "    (rowDomain, colDomain, cMatrix) = get_contingencyMatrix(dataset, H, E)\n",
    "\n",
    "    len_rowDomain, len_colDomain = len(rowDomain), len(colDomain)\n",
    "    E_marginal = np.zeros(len_colDomain)\n",
    "    for col in range(len_colDomain):\n",
    "        E_marginal[col] = sum(cMatrix[:, col])\n",
    "\n",
    "    for row in range(len_rowDomain):\n",
    "        for col in range(len_colDomain):\n",
    "            cMatrix[row, col] = cMatrix[row, col] / E_marginal[col]\n",
    "    return (rowDomain, colDomain, cMatrix)\n",
    "\n",
    "\n",
    "# _______________________________________________________________________________\n",
    "# 1R Related Functions\n",
    "# _______________________________________________________________________________\n",
    "# error matrix for a given feature and considering the datatset class\n",
    "def get_errorMatrix(dataset, feature):\n",
    "    if(isinstance(feature, str)):\n",
    "        feature = get_variableFrom_str(dataset, feature)\n",
    "    the_class = dataset.domain.class_var\n",
    "    (rowDomain, colDomain, cMatrix) = get_conditionalProbability(dataset, the_class, feature)\n",
    "    if(not (rowDomain or colDomain)):\n",
    "        return ([], [], None)\n",
    "\n",
    "    errorMatrix = 1 - cMatrix\n",
    "    return (rowDomain, colDomain, errorMatrix)\n",
    "\n",
    "\n",
    "# _______________________________________________________________________________\n",
    "# Data Presentation Functions\n",
    "# _______________________________________________________________________________\n",
    "# show contingency matrix\n",
    "def show_contingencyMatrix(dataset, rowVar, colVar):\n",
    "    my_print(\"{} & {} :\".format(rowVar.name, colVar.name))\n",
    "    (rowDomain, colDomain, cMatrix) = get_contingencyMatrix(dataset, rowVar, colVar)\n",
    "    print(cMatrix)\n",
    "    for row in rowDomain:\n",
    "        showStr = \"<\" + row + \"> \"\n",
    "        for col in colDomain:\n",
    "            showStr += col + \": \" + str(cMatrix[rowDomain.index(row), colDomain.index(col)]) + \" | \"\n",
    "        print(showStr)\n",
    "\n",
    "\n",
    "# _______________________________________________________________________________\n",
    "# show all contingency matrix\n",
    "# - for each feature and the class\n",
    "def showAll_contingencyMatrix(dataset):\n",
    "    feature_list, the_class = dataset.domain.attributes, dataset.domain.class_var\n",
    "    for feature in feature_list:\n",
    "        show_contingencyMatrix(dataset, feature, the_class)\n",
    "        print()\n",
    "\n",
    "\n",
    "# _______________________________________________________________________________\n",
    "# P( H | E )\n",
    "# show matriz and textual description\n",
    "def show_conditionalProbability(dataset, H, E):\n",
    "    (rowDomain, colDomain, cMatrix) = get_conditionalProbability(dataset, H, E)\n",
    "    print(cMatrix)\n",
    "    print()\n",
    "\n",
    "    for h in rowDomain:\n",
    "        for e in colDomain:\n",
    "            rowIndex, colIndex = rowDomain.index(h), colDomain.index(e)\n",
    "            P_h_e = cMatrix[rowIndex, colIndex]\n",
    "            print(\"  P({} | {}) = {:.3f}\".format(h, e, P_h_e))\n",
    "\n",
    "\n",
    "def getLowestErrorFeature(dataset):\n",
    "    errors = {}\n",
    "\n",
    "    feature_list, the_class = dataset.domain.attributes, dataset.domain.class_var\n",
    "    for feature in feature_list:\n",
    "        (rowDomain, colDomain, cMatrix) = get_contingencyMatrix(dataset, feature, the_class)\n",
    "\n",
    "        valueError = 0\n",
    "        errors[feature.name] = 0\n",
    "        for row in rowDomain:\n",
    "            freqs = cMatrix[rowDomain.index(row), :]\n",
    "            rowTotal = sum(freqs)\n",
    "            valueError += rowTotal - max(freqs)\n",
    "            errors[feature.name] += rowTotal\n",
    "        errors[feature.name] = valueError / errors[feature.name]\n",
    "\n",
    "    for feature in errors:\n",
    "        if(errors[feature] == min(errors.values())):\n",
    "            return feature\n",
    "\n",
    "\n",
    "# _______________________________________________________________________________\n",
    "# implementation of some test cases\n",
    "def test():\n",
    "    fileName = \"./Scripts/fpa_dataset\"\n",
    "    # fileName = \"./Scripts/lenses_fromLecture\"\n",
    "    dataset = load(fileName)\n",
    "\n",
    "    # print()\n",
    "    # aStr = \">> Percentage of missing values per variable <<\"\n",
    "    # my_print(aStr)\n",
    "    # (variable_list, missingValue_list) = get_missingValuePercentage(dataset)\n",
    "    # for i in range(len(variable_list)):\n",
    "    #     print(\"%4.1f%s %s\" % (missingValue_list[i], '%', variable_list[i].name))\n",
    "\n",
    "    # print()\n",
    "    # aStr = \">> Contingency Matrix <<\"\n",
    "    # my_print(aStr)\n",
    "    # showAll_contingencyMatrix(dataset)\n",
    "\n",
    "    # print()\n",
    "    # H = \"lenses\"\n",
    "    # E = \"age\"\n",
    "    # aStr = \">> P( %s | %s ) <<\" % (H, E)\n",
    "    # my_print(aStr)\n",
    "    # show_conditionalProbability(dataset, H, E)\n",
    "\n",
    "    print()\n",
    "    the_feature = getLowestErrorFeature(dataset)\n",
    "    aStr = \"(1R-approach) >>Error Matrix>> %s & %s <<\" % (the_feature, dataset.domain.class_var)\n",
    "    my_print(aStr)\n",
    "    (classDomain, featureDomain, errorMatrix) = get_errorMatrix(dataset, the_feature)\n",
    "    if(not (classDomain or featureDomain)):\n",
    "        return\n",
    "    print(classDomain)\n",
    "    print(featureDomain)\n",
    "    print(errorMatrix)\n",
    "    print()\n",
    "    print(\"1R for the '{}' feature are:\".format(the_feature))\n",
    "    for feature in range(len(featureDomain)):\n",
    "        errorFeature = errorMatrix[:, feature]\n",
    "        errorMin = min(errorFeature)\n",
    "        errorMinIndex = errorFeature.tolist().index(errorMin)\n",
    "        featureValue = featureDomain[feature]\n",
    "        classValue = classDomain[errorMinIndex]\n",
    "        showStr = \"(\" + the_feature + \", \" + featureValue + \", \" + classValue + \") : \"\n",
    "        print(showStr + \"{:.3f}\".format(errorMin))\n",
    "\n",
    "\n",
    "# _______________________________________________________________________________\n",
    "# the main of this module (in case this module is imported from another module)\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cabe134d8dd6ea57adc5d20c1ae84d41ce1f40145ba4c9707391b6a73b5ce04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
